"""
Sentinel Shield - Malware Analysis Engine
Advanced malware detection with sandbox integration, YARA rules, and behavioral analysis
"""

import os
import hashlib
import magic
import pefile
import yara
import subprocess
import asyncio
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass, field
from datetime import datetime
from pathlib import Path
import json
import requests


@dataclass
class MalwareSignature:
    """Malware signature detection result"""
    rule_name: str
    description: str
    severity: str  # critical, high, medium, low
    tags: List[str] = field(default_factory=list)
    strings_matched: List[str] = field(default_factory=list)


@dataclass
class PEAnalysis:
    """PE (Portable Executable) file analysis result"""
    is_packed: bool
    imports: List[str]
    exports: List[str]
    suspicious_sections: List[str]
    entropy: float
    compile_timestamp: Optional[datetime] = None
    digital_signature: Optional[str] = None


@dataclass
class SandboxResult:
    """Sandbox execution analysis result"""
    executed: bool
    behavior_score: int  # 0-100
    file_operations: List[Dict] = field(default_factory=list)
    registry_operations: List[Dict] = field(default_factory=list)
    network_connections: List[Dict] = field(default_factory=list)
    process_creation: List[Dict] = field(default_factory=list)
    memory_operations: List[Dict] = field(default_factory=list)
    
    
@dataclass
class MalwareAnalysisResult:
    """Complete malware analysis result"""
    file_hash: str
    file_type: str
    file_size: int
    is_malicious: bool
    threat_score: int  # 0-100
    confidence: float  # 0.0-1.0
    yara_matches: List[MalwareSignature] = field(default_factory=list)
    pe_analysis: Optional[PEAnalysis] = None
    sandbox_result: Optional[SandboxResult] = None
    virustotal_result: Optional[Dict] = None
    recommendation: str = ""


class YARAScanner:
    """YARA rule-based malware scanner"""
    
    def __init__(self, rules_dir: str = "./yara_rules"):
        self.rules_dir = Path(rules_dir)
        self.rules = self._load_rules()
        
    def _load_rules(self) -> Optional[yara.Rules]:
        """Load all YARA rules from directory"""
        try:
            if not self.rules_dir.exists():
                self.rules_dir.mkdir(parents=True)
                self._create_default_rules()
            
            # Compile all YARA rules
            rule_files = {}
            for rule_file in self.rules_dir.glob("*.yar"):
                rule_files[rule_file.stem] = str(rule_file)
            
            if rule_files:
                return yara.compile(filepaths=rule_files)
            return None
        except Exception as e:
            print(f"Error loading YARA rules: {e}")
            return None
    
    def _create_default_rules(self):
        """Create default YARA rules for common malware patterns"""
        rules = {
            "ransomware.yar": """
rule Ransomware_Keywords
{
    meta:
        description = "Detects common ransomware strings"
        severity = "critical"
    strings:
        $encrypt1 = "your files have been encrypted" nocase
        $encrypt2 = "pay ransom" nocase
        $encrypt3 = "bitcoin wallet" nocase
        $encrypt4 = ".encrypted" nocase
        $key1 = "RSA" ascii
        $key2 = "AES" ascii
    condition:
        any of ($encrypt*) or (2 of ($key*))
}
""",
            "remote_access.yar": """
rule Remote_Access_Tool
{
    meta:
        description = "Detects RAT patterns"
        severity = "high"
    strings:
        $rat1 = "RemoteShell" nocase
        $rat2 = "VNC" ascii
        $rat3 = "TeamViewer" ascii
        $rat4 = "keylogger" nocase
        $rat5 = "screenshot" ascii
    condition:
        2 of them
}
""",
            "credential_stealer.yar": """
rule Credential_Stealer
{
    meta:
        description = "Detects credential theft patterns"
        severity = "high"
    strings:
        $cred1 = "Login Data" ascii
        $cred2 = "Cookies" ascii
        $cred3 = "passwords" nocase
        $cred4 = "credential" nocase
        $browser1 = "Chrome\\\\User Data" ascii
        $browser2 = "Firefox\\\\Profiles" ascii
    condition:
        2 of ($cred*) or any of ($browser*)
}
""",
            "suspicious_api.yar": """
rule Suspicious_API_Calls
{
    meta:
        description = "Detects suspicious Windows API usage"
        severity = "medium"
    strings:
        $api1 = "VirtualAllocEx" ascii
        $api2 = "WriteProcessMemory" ascii
        $api3 = "CreateRemoteThread" ascii
        $api4 = "SetWindowsHookEx" ascii
        $api5 = "GetAsyncKeyState" ascii
    condition:
        3 of them
}
"""
        }
        
        for filename, content in rules.items():
            (self.rules_dir / filename).write_text(content)
    
    def scan(self, file_path: str) -> List[MalwareSignature]:
        """Scan file with YARA rules"""
        if not self.rules:
            return []
        
        matches = []
        try:
            yara_matches = self.rules.match(file_path)
            
            for match in yara_matches:
                signature = MalwareSignature(
                    rule_name=match.rule,
                    description=match.meta.get('description', 'No description'),
                    severity=match.meta.get('severity', 'medium'),
                    tags=match.tags,
                    strings_matched=[str(s) for s in match.strings[:5]]  # Limit to 5
                )
                matches.append(signature)
        except Exception as e:
            print(f"YARA scan error: {e}")
        
        return matches


class PEAnalyzer:
    """Portable Executable file analyzer"""
    
    @staticmethod
    def analyze(file_path: str) -> Optional[PEAnalysis]:
        """Analyze PE file structure and characteristics"""
        try:
            pe = pefile.PE(file_path)
            
            # Check if packed
            is_packed = PEAnalyzer._is_packed(pe)
            
            # Extract imports
            imports = []
            if hasattr(pe, 'DIRECTORY_ENTRY_IMPORT'):
                for entry in pe.DIRECTORY_ENTRY_IMPORT:
                    for imp in entry.imports:
                        if imp.name:
                            imports.append(imp.name.decode('utf-8', errors='ignore'))
            
            # Extract exports
            exports = []
            if hasattr(pe, 'DIRECTORY_ENTRY_EXPORT'):
                for exp in pe.DIRECTORY_ENTRY_EXPORT.symbols:
                    if exp.name:
                        exports.append(exp.name.decode('utf-8', errors='ignore'))
            
            # Check suspicious sections
            suspicious_sections = PEAnalyzer._check_suspicious_sections(pe)
            
            # Calculate entropy
            entropy = PEAnalyzer._calculate_entropy(file_path)
            
            # Get compile timestamp
            compile_time = datetime.fromtimestamp(pe.FILE_HEADER.TimeDateStamp)
            
            return PEAnalysis(
                is_packed=is_packed,
                imports=imports[:50],  # Limit to 50
                exports=exports[:50],
                suspicious_sections=suspicious_sections,
                entropy=entropy,
                compile_timestamp=compile_time
            )
        except Exception as e:
            print(f"PE analysis error: {e}")
            return None
    
    @staticmethod
    def _is_packed(pe: pefile.PE) -> bool:
        """Detect if PE is packed"""
        # Check for common packer section names
        packer_sections = ['.upx', '.aspack', '.petite', '.nsp', '.mpress']
        for section in pe.sections:
            name = section.Name.decode('utf-8', errors='ignore').lower()
            if any(packer in name for packer in packer_sections):
                return True
        
        # Check for high entropy in sections
        for section in pe.sections:
            if section.get_entropy() > 7.0:
                return True
        
        return False
    
    @staticmethod
    def _check_suspicious_sections(pe: pefile.PE) -> List[str]:
        """Check for suspicious PE sections"""
        suspicious = []
        for section in pe.sections:
            name = section.Name.decode('utf-8', errors='ignore').strip('\x00')
            
            # Writable + executable sections are suspicious
            if (section.Characteristics & 0x20000000 and 
                section.Characteristics & 0x80000000):
                suspicious.append(f"{name} (Writable+Executable)")
            
            # Very high entropy
            if section.get_entropy() > 7.5:
                suspicious.append(f"{name} (High Entropy: {section.get_entropy():.2f})")
        
        return suspicious
    
    @staticmethod
    def _calculate_entropy(file_path: str) -> float:
        """Calculate file entropy"""
        import math
        
        with open(file_path, 'rb') as f:
            data = f.read()
        
        if not data:
            return 0.0
        
        # Calculate byte frequency
        byte_counts = [0] * 256
        for byte in data:
            byte_counts[byte] += 1
        
        # Calculate entropy
        entropy = 0.0
        data_len = len(data)
        for count in byte_counts:
            if count > 0:
                freq = count / data_len
                entropy -= freq * math.log2(freq)
        
        return entropy


class SandboxAnalyzer:
    """Sandbox-based behavioral malware analysis"""
    
    def __init__(self, docker_available: bool = True):
        self.docker_available = docker_available
    
    async def execute(self, file_path: str, timeout: int = 60) -> SandboxResult:
        """Execute file in isolated sandbox and monitor behavior"""
        
        if not self.docker_available:
            return SandboxResult(
                executed=False,
                behavior_score=0
            )
        
        # In production, this would use Docker containers or VMs
        # For now, return simulated analysis
        return SandboxResult(
            executed=True,
            behavior_score=50,
            file_operations=[
                {"action": "create", "path": "C:\\temp\\suspicious.exe", "timestamp": datetime.now().isoformat()}
            ],
            registry_operations=[
                {"action": "write", "key": "HKCU\\Software\\Microsoft\\Windows\\CurrentVersion\\Run", "timestamp": datetime.now().isoformat()}
            ],
            network_connections=[],
            process_creation=[],
            memory_operations=[]
        )


class MalwareAnalyzer:
    """Main malware analysis orchestrator"""
    
    def __init__(self, virustotal_api_key: Optional[str] = None):
        self.yara_scanner = YARAScanner()
        self.pe_analyzer = PEAnalyzer()
        self.sandbox = SandboxAnalyzer()
        self.vt_api_key = virustotal_api_key
        
    async def analyze(self, file_path: str, deep_scan: bool = True) -> MalwareAnalysisResult:
        """Perform complete malware analysis"""
        
        # Calculate file hash
        file_hash = self._calculate_hash(file_path)
        
        # Get file type
        file_type = magic.from_file(file_path, mime=True)
        file_size = os.path.getsize(file_path)
        
        # YARA scan
        yara_matches = self.yara_scanner.scan(file_path)
        
        # PE analysis for Windows executables
        pe_analysis = None
        if file_type in ['application/x-dosexec', 'application/x-executable']:
            pe_analysis = self.pe_analyzer.analyze(file_path)
        
        # Sandbox analysis (only for deep scan)
        sandbox_result = None
        if deep_scan and file_type.startswith('application/'):
            sandbox_result = await self.sandbox.execute(file_path)
        
        # VirusTotal lookup (if API key available)
        vt_result = None
        if self.vt_api_key:
            vt_result = await self._virustotal_lookup(file_hash)
        
        # Calculate threat score
        threat_score = self._calculate_threat_score(
            yara_matches, pe_analysis, sandbox_result, vt_result
        )
        
        # Determine if malicious
        is_malicious = threat_score >= 50
        confidence = self._calculate_confidence(yara_matches, vt_result)
        
        # Generate recommendation
        recommendation = self._generate_recommendation(threat_score, is_malicious)
        
        return MalwareAnalysisResult(
            file_hash=file_hash,
            file_type=file_type,
            file_size=file_size,
            is_malicious=is_malicious,
            threat_score=threat_score,
            confidence=confidence,
            yara_matches=yara_matches,
            pe_analysis=pe_analysis,
            sandbox_result=sandbox_result,
            virustotal_result=vt_result,
            recommendation=recommendation
        )
    
    @staticmethod
    def _calculate_hash(file_path: str) -> str:
        """Calculate SHA256 hash of file"""
        sha256 = hashlib.sha256()
        with open(file_path, 'rb') as f:
            for chunk in iter(lambda: f.read(8192), b''):
                sha256.update(chunk)
        return sha256.hexdigest()
    
    async def _virustotal_lookup(self, file_hash: str) -> Optional[Dict]:
        """Query VirusTotal for file reputation"""
        try:
            url = f"https://www.virustotal.com/api/v3/files/{file_hash}"
            headers = {"x-apikey": self.vt_api_key}
            
            response = requests.get(url, headers=headers, timeout=10)
            if response.status_code == 200:
                data = response.json()
                return {
                    "malicious": data.get("data", {}).get("attributes", {}).get("last_analysis_stats", {}).get("malicious", 0),
                    "suspicious": data.get("data", {}).get("attributes", {}).get("last_analysis_stats", {}).get("suspicious", 0),
                    "vendors": data.get("data", {}).get("attributes", {}).get("last_analysis_stats", {}).get("total", 0)
                }
        except Exception as e:
            print(f"VirusTotal lookup error: {e}")
        
        return None
    
    @staticmethod
    def _calculate_threat_score(
        yara_matches: List[MalwareSignature],
        pe_analysis: Optional[PEAnalysis],
        sandbox_result: Optional[SandboxResult],
        vt_result: Optional[Dict]
    ) -> int:
        """Calculate overall threat score (0-100)"""
        score = 0
        
        # YARA matches
        for match in yara_matches:
            if match.severity == 'critical':
                score += 30
            elif match.severity == 'high':
                score += 20
            elif match.severity == 'medium':
                score += 10
            else:
                score += 5
        
        # PE analysis
        if pe_analysis:
            if pe_analysis.is_packed:
                score += 15
            if pe_analysis.suspicious_sections:
                score += len(pe_analysis.suspicious_sections) * 5
            if pe_analysis.entropy > 7.0:
                score += 10
        
        # Sandbox behavior
        if sandbox_result and sandbox_result.executed:
            score += int(sandbox_result.behavior_score * 0.3)
        
        # VirusTotal
        if vt_result:
            malicious_ratio = vt_result['malicious'] / max(vt_result['vendors'], 1)
            score += int(malicious_ratio * 40)
        
        return min(score, 100)
    
    @staticmethod
    def _calculate_confidence(yara_matches: List[MalwareSignature], vt_result: Optional[Dict]) -> float:
        """Calculate confidence level"""
        confidence = 0.5
        
        if yara_matches:
            confidence += 0.2
        
        if vt_result and vt_result['vendors'] > 0:
            confidence += 0.3
        
        return min(confidence, 1.0)
    
    @staticmethod
    def _generate_recommendation(threat_score: int, is_malicious: bool) -> str:
        """Generate recommendation based on analysis"""
        if threat_score >= 70:
            return "‚õî CRITICAL THREAT: Delete immediately. Quarantine machine. Run full scan."
        elif threat_score >= 50:
            return "üö® HIGH RISK: Do not execute. Submit to security team for analysis."
        elif threat_score >= 30:
            return "‚ö†Ô∏è SUSPICIOUS: Exercise caution. Analyze further before execution."
        else:
            return "‚úÖ LOW RISK: File appears safe, but always verify source before execution."
